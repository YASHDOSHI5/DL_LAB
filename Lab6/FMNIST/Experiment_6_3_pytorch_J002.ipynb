{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Pytorch for Deeplearning",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Copy of fashion-mnist-with-alexnet-in-pytorch-92-accuracy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gtpbQa9e1Km"
      },
      "source": [
        "# Before\n",
        "It's my first time to creat a neural network, please correct me if there is anything wrong in the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y6YnQPE_d3f"
      },
      "source": [
        "# About Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKcAz7t9_d3i"
      },
      "source": [
        "Here are the categories in the Fashion-MNIST\n",
        "\n",
        "|Label | Class |\n",
        "|-|-|\n",
        "|0|\tT-shirt/top|\n",
        "|1|\tTrouser|\n",
        "|2|\tPullover|\n",
        "|3|\tDress|\n",
        "|4|\tCoat|\n",
        "|5|\tSandal|\n",
        "|6|\tShirt|\n",
        "|7|\tSneaker|\n",
        "|8|\tBag|\n",
        "|9|\tAnkle boot|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjIkpjNce1Kr"
      },
      "source": [
        "# Ready to work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so9k_W_C_d3j",
        "trusted": true
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9KJh0ZDe1Kt"
      },
      "source": [
        "Define some global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R6JY6DMMe1Kt"
      },
      "source": [
        "# training batches of our network\n",
        "EPOCHS = 10\n",
        "# size of each batch\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "DEVICE = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print(torch.__version__)\n",
        "print(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcnXRreC_d3o"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnPHX1dYe1Ku"
      },
      "source": [
        "There are two ways to laod the Fashion-MNIST dataset:\n",
        "\n",
        "* use the dataset given in the `datasets.FashionMNIST`\n",
        "* use raw data \n",
        "\n",
        "Here I use the data on Kaggle, so we need to build the `dataset`\n",
        "\n",
        "Firstly, import the '.csv' files with `pd.read_csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa4spfPd_d3p",
        "trusted": true
      },
      "source": [
        "train_csv = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv')\n",
        "test_csv = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv')\n",
        "\n",
        "\n",
        "print(train_csv.shape)\n",
        "print(test_csv.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI5Ce0bx_d3x",
        "trusted": true
      },
      "source": [
        "print(train_csv.info())\n",
        "print(train_csv.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DocWsneXe1Kv"
      },
      "source": [
        "As the output, the first row is the label of each image, and each image has 784 pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yD8waIle1Kv"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKOUAY4s_d37"
      },
      "source": [
        "To build our own dataset, need to create a class that inherits from the `Dataset`. Besides, function `get_item()` & `len()` must be defined at least\n",
        "\n",
        "- `get_item()` return the specified image and its label\n",
        "- `len()` return the number of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzgxwITL_d38",
        "trusted": true
      },
      "source": [
        "class FashionDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):        \n",
        "        self.fashion_MNIST = list(data.values)\n",
        "        self.transform = transform\n",
        "        \n",
        "        label, image = [], []\n",
        "        \n",
        "        for i in self.fashion_MNIST:\n",
        "            label.append(i[0])\n",
        "            image.append(i[1:])\n",
        "        self.labels = np.asarray(label)\n",
        "        self.images = np.asarray(image).reshape(-1, 28, 28).astype('float32')\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        image = self.images[idx]      \n",
        "        \n",
        "        if self.transform is not None:\n",
        "            # transfrom the numpy array to PIL image before the transform function\n",
        "            pil_image = Image.fromarray(np.uint8(image)) \n",
        "            image = self.transform(pil_image)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHsZTqRVe1Kw"
      },
      "source": [
        "## Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpej90-i_d3_"
      },
      "source": [
        "Because the input size of AlexNet is $227*227$, and the image size of Fashion-MNIST is $28*28$, so we need to resize the image in the transform function\n",
        "> Since `transforms.Resize()` only works to the PIL Image,we transform the numpy array to PIL Image above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_xGJIzw_d4A",
        "trusted": true
      },
      "source": [
        "AlexTransform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1firajBn_d4E"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbxiLT1f_d4F",
        "trusted": true
      },
      "source": [
        "train_loader = DataLoader(\n",
        "    FashionDataset(train_csv, transform=AlexTransform), \n",
        "    batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    FashionDataset(test_csv, transform=AlexTransform), \n",
        "    batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOL8Q8j3e1Kx"
      },
      "source": [
        "## Show images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qqdpdORhe1Kx"
      },
      "source": [
        "# helper function to show an image\n",
        "def matplotlib_imshow(img):\n",
        "    img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(npimg, cmap=\"Greys\")\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# creat grid of images\n",
        "img_grid = torchvision.utils.make_grid(images[0])\n",
        "\n",
        "# show images & labels\n",
        "matplotlib_imshow(img_grid)\n",
        "print(class_names[labels[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJPnzI7O_d4I"
      },
      "source": [
        "# AlexNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PILwGoTAe1Ky"
      },
      "source": [
        "![](https://i.loli.net/2020/02/17/xd6oNRpWSK1cZy2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAi4_TFU_d4J",
        "trusted": true
      },
      "source": [
        "class fasion_mnist_alexnet(nn.Module):  \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = self.fc3(out)\n",
        "        out = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htbYHgHnZP0r"
      },
      "source": [
        "# model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SqUo_21_d4M",
        "trusted": true
      },
      "source": [
        "model = fasion_mnist_alexnet().to(DEVICE)\n",
        "criterion = F.nll_loss\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOhyXpQNZUVI"
      },
      "source": [
        "## train funation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X8gTFBh_d4O",
        "trusted": true
      },
      "source": [
        "def train(model, device, train_loader, optimer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        target = target.type(torch.LongTensor)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % 30 == 0:\n",
        "            print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4cCPiOPZXkC"
      },
      "source": [
        "## test function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGhwH-H-_d4S",
        "trusted": true
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target, reduction='sum').item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(test_loader.dataset)  # loss之和除以data数量 -> mean\n",
        "        print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "            test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "        print('='*50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy6-W8TFZa-5"
      },
      "source": [
        "# Begin to Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy6cq2T2_d4V",
        "trusted": true
      },
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
        "    test(model, DEVICE, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKFQUq_Ke1K8"
      },
      "source": [
        "After 10 epochs, we get 92% accuracy. I also run 20 epochs on the Colab but still 92% accuracy. \n",
        "\n",
        "The Net completely from AlexNet, this maybe a bit overkill but I just use it to learn. \n",
        "\n",
        "Happy to get some suggests about the net or notebook!"
      ]
    }
  ]
}